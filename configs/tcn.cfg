# config for TCN AE/VAE (Autoregressive)
accelerator: 'gpu'
num_devices: 1
training: True
dataloader: 'prometheus'
checkpoint: ''
resume_training: False
project_name: 'om2vec-dev'
project_save_dir: '/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/om2vec-dev'
model_options:
    architecture: 'tcn' # Added for clarity, though factory might infer from filename
    seq_len: 6400          # Matches num_bins, used instead of in_features for TCN
    latent_dim: 64
    tcn_channels: [64, 64, 64, 64]
    tcn_kernel_size: 3
    tcn_dropout: 0.1
    # VAE options (set is_vae=True to enable)
    is_vae: False
    beta_schedule: 'constant' # 'none', 'constant', 'annealed'
    beta_factor: 0.00001    # Relevant if beta_schedule='constant' or 'annealed'
    beta_peak_epoch: 4      # Relevant if beta_schedule='annealed' (can be omitted if schedule is 'constant')
data_options:
    train_data_files: ['/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/nt_vae_data/IceCube_HE/NuMu/', 
                      '/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/nt_vae_data/IceCube_HE/EMinus/',
                      '/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/nt_vae_data/IceCube_HE/MuMinus/',
                      '/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/nt_vae_data/IceCube_HE/TauMinus/']
    train_data_file_ranges: [[0, 19], [0, 19], [0, 29], [0, 12]]
    valid_data_files: ['/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/nt_vae_data/IceCube_HE/MuMinus/']
    valid_data_file_ranges: [[30, 34]]
    file_chunk_size: 250000
training_options:
    batch_size: 1024
    lr: 0.0001
    lr_schedule: []
    weight_decay: 0.01
    epochs: 25
    save_epochs: 5
    num_workers: 2
    teacher_forcing_ratio: 0.5 # Added for autoregressive training