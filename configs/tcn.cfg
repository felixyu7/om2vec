# config for TCN AE/VAE (Autoregressive)
accelerator: 'gpu'
num_devices: 1
training: True
dataloader: 'prometheus'
checkpoint: ''
resume_training: False
project_name: 'example_tcn'
project_save_dir: '/path/to/wandb_project_save_dir/example_tcn'
model_options:
    architecture: 'tcn' # Added for clarity, though factory might infer from filename
    seq_len: 6400          # Matches num_bins, used instead of in_features for TCN
    latent_dim: 64
    tcn_channels: [64, 64, 64, 64]
    tcn_kernel_size: 3
    tcn_dropout: 0.1
    # VAE options (set is_vae=True to enable)
    is_vae: False
    beta_schedule: 'constant' # 'none', 'constant', 'annealed'
    beta_factor: 0.00001    # Relevant if beta_schedule='constant' or 'annealed'
    beta_peak_epoch: 4      # Relevant if beta_schedule='annealed' (can be omitted if schedule is 'constant')
data_options:
    train_data_files: ['/dataset/directory/1/',
                       '/dataset/directory/2/']
    train_data_file_ranges: [[0, 19], [0, 9]]
    valid_data_files: ['/dataset/directory/1/',
                       '/dataset/directory/2/']
    valid_data_file_ranges: [[20, 24], [10, 14]]
    file_chunk_size: 250000
training_options:
    batch_size: 1024
    lr: 0.0001
    lr_schedule: []
    weight_decay: 0.01
    epochs: 25
    save_epochs: 5
    num_workers: 2
    teacher_forcing_ratio: 0.5 # Added for autoregressive training