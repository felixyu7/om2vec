accelerator: 'gpu'
num_devices: 1
training: True
dataloader: 'prometheus'
checkpoint: ''
resume_training: False
project_name: 'om2vec'
project_save_dir: './experiment_logs'
logger: 'wandb'
model_options:
    latent_dim: 64  # Total latent dimension (4 summary stats)
    embed_dim: 128
    alpha: 1.0
    lambda_: 100.0
    # Loss weights for different components
    charge_wasserstein_loss_weight: 1.0
    interval_wasserstein_loss_weight: 1.0
    # PyTorch Transformer Encoder HParams
    transformer_encoder_layers: 4
    transformer_encoder_heads: 8
    transformer_encoder_ff_dim: 1024
    transformer_encoder_dropout: 0.
    # PyTorch Transformer Decoder HParams
    transformer_decoder_layers: 4
    transformer_decoder_heads: 8
    transformer_decoder_ff_dim: 1024
    transformer_decoder_dropout: 0.
    
data_options:
    train_data_files: ["/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/combined/"]
    valid_data_files: ["/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/combined_test/"]
    train_data_file_ranges: [[0, 809]] # Ranges for each file in train_data_files
    valid_data_file_ranges: [[0, 80]] # Ranges for each file in valid_data_files
    shuffle_files: True
    max_seq_len_padding: 1024
    grouping_window_ns: 2.0
    # Epsilon for log normalization (small value to avoid log(0))
    log_epsilon: 1e-8

training_options:
    batch_size: 1024
    lr: 0.0001
    lr_schedule: [10, 0.000001]
    weight_decay: 0.0001
    gradient_clip_val: 1.0
    precision: 'bf16-true'
    test_precision: 'bf16-true'
    epochs: 10
    save_epochs: 1
    num_workers: 8