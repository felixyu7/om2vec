project_name: "om2vec"
project_save_dir: "./wandb_logs" # Local directory for logs & checkpoints
training: true                      # true: train; false: test
accelerator: "gpu"                  # "gpu" or "cpu"
num_devices: 1                      # number of devices (GPUs)
dataloader: "prometheus"     # key matching a DataModule class in dataloaders/
checkpoint: ""                      # path to ckpt or empty
resume_training: false              # whether to resume if checkpoint provided
logger: "csv"

data_options:
  train_data_files: ["/Users/felixyu/icecube/data/prometheus_om2vec/"]
  valid_data_files: ["/Users/felixyu/icecube/data/prometheus_om2vec/"] # initially, or specify validation files
  train_data_file_ranges: [[0, 2]]
  valid_data_file_ranges: [[0, 2]]
  shuffle_files: true # If true, shuffles file order each epoch for training set
  max_seq_len: 512      # For padding/truncating photon sequences per sensor
  summary_stats_dim: 10 # Number of summary statistics

model_options:
  latent_dim_learned: 64 # Dimension for z_learned
  transformer_d_model: 256
  transformer_nhead: 8
  transformer_num_encoder_layers: 6
  transformer_dim_feedforward: 1024
  zuko_nsf_hidden_features: 128 # For zuko NSF conditioner/transforms internal MLPs
  zuko_nsf_num_flow_steps: 5    # Number of NSF blocks
  zuko_nsf_num_bins: 8          # Number of bins for rational quadratic splines

training_options:
  batch_size: 64
  lr: 1.0e-4
  # lr_schedule: [100, 1.0e-6]      # Example: CosineAnnealingLR T_max=100, eta_min=1e-6 (match epochs)
  weight_decay: 1.0e-5
  epochs: 100
  save_epochs: 5                # Save checkpoint every N epochs
  save_top_k: 3                 # Save top K checkpoints based on monitor_metric
  monitor_metric: "val_loss"    # Metric to monitor for saving checkpoints
  monitor_mode: "min"           # "min" or "max" for monitor_metric
  num_workers: 4
  precision: "bf16-mixed"       # "bf16-mixed", "32-true", "16-mixed"
  test_precision: "bf16-mixed"  # Precision for test mode