project_name: "om2vec"
project_save_dir: "./experiment_logs"
training: true
accelerator: "gpu" # or "cpu"
num_devices: 1
logger: "csv"
dataloader: "icecube_parquet" # Corresponds to IcecubeParquetDataModule in dataloaders/
model_name: "om2vec_model"    # Corresponds to Om2vecModel in models/

data_options:
  train_data_files: ["/Users/felixyu/icecube/neptune-omni/data/"]
  train_data_file_ranges: [[0, 2]] # Optional: [[0, 10000], [0, 5000]]
  valid_data_files: ["/Users/felixyu/icecube/neptune-omni/data/"]
  valid_data_file_ranges: [[0, 2]]  # Optional: [[0, 2000]]
  shuffle_files: true
  cache_size: 20 # Number of parquet files to cache in memory
  # New options for om2vec
  max_oms_per_event: 50       # Max OMs to process from one event (for padding/truncation)
  max_photons_per_om: 128     # Max (t,q) hits per OM for Transformer input (padding/truncation)
  # Normalization parameters for t, q, sensor_pos (e.g., means, stds, or min/max for scaling)
  # These might be pre-calculated or set based on dataset knowledge.
  # Example values, adjust based on your data:
  tq_log_norm_offset: 1.0     # for log(x + offset) normalization of t and q
  sensor_pos_norm_scale: 600.0 # Example: if sensor positions are in meters, scale by approximate detector radius

model_options:
  # VAE-Transformer Encoder
  input_embedding_dim: 64
  transformer_hidden_dim: 256
  transformer_num_heads: 8
  transformer_num_layers: 6
  transformer_dropout: 0.1
  pooling_strategy: "mean" # "cls" or "mean"
  latent_learned_dim: 16   # Dimensionality of z_learned (total z_dim = 9 summary_stats + latent_learned_dim)
  # Sensor position integration
  sensor_pos_embedding_dim: 32 # If sensor_pos is embedded before use in Transformer/CNF
  sensor_integration_type: "film" # Options: "film", "cross_attention", "concat_to_transformer_input", "decoder_only", "none"

  # CNF Decoder (using nflows)
  cnf_condition_on_sensor_pos: false # CNF will not condition on sensor position
  cnf_base_dist_dim: 1 # Univariate time t
  cnf_num_layers: 5    # Number of NSF layers
  cnf_hidden_dims_hypernet: [128, 128] # For hypernetwork generating spline params for nflows
  cnf_num_bins_spline: 10 # Number of bins for rational quadratic splines in nflows
  # cnf_context_dim will be dynamically calculated in the model:
  # latent_learned_dim + 9 (summary_stats) + (sensor_pos_embedding_dim if used for CNF conditioning)

training_options:
  batch_size: 32 # Number of events per batch
  lr: 0.0001
  lr_schedule_t_max: 500 # For CosineAnnealingLR (e.g., total epochs)
  lr_schedule_eta_min: 0.000001 # Target LR for CosineAnnealingLR
  weight_decay: 0.01
  epochs: 500
  save_epochs: 10 # Save checkpoint every N epochs
  num_workers: 4  # Dataloader workers
  precision: "32-true" # "32-true", "16-mixed", "bf16-mixed"
  test_precision: "32-true"
  # Gradient clipping if needed
  # grad_clip_val: 1.0

  # KL Annealing for VAE
  kl_beta_initial_value: 0.0
  kl_beta_final_value: 1.0
  kl_anneal_epochs: 50 # Number of epochs to reach kl_beta_final_value from initial_value
  kl_anneal_schedule: "linear" # "linear", "cosine" (initially linear)