project_name: "om2vec"
project_save_dir: "./experiment_logs" # Default save directory
training: true
accelerator: "gpu" # or "cpu"
num_devices: 1
dataloader: "prometheus"
model_name: "om2vec"
checkpoint: "" # path to ckpt or empty
resume_training: false
logger: "csv"

data_options:
  train_data_files: ["/Users/felixyu/icecube/data/prometheus_om2vec/"] # Corrected: flat list
  train_data_file_ranges: [[0, 2]] # Optional: [[start,end], ...]
  valid_data_files: ["/Users/felixyu/icecube/data/prometheus_om2vec/"] # Corrected: flat list
  valid_data_file_ranges: [[0, 2]] # Optional: [[start,end], ...]
  shuffle_files: true
  time_column: 'hits_t'
  # charge_column_name: 'photon_count' # This is conceptual for the dataloader, not a direct column name from file
  grouping_window_ns: 3.0
  max_seq_len_padding: 512 # For collate_fn padding limit

model_options:
  latent_dim: 32
  event_input_dim: 2 # (log_inter_event_time, log_charge) for NTPP decoder input
  rnn_hidden_dim: 128
  rnn_num_layers: 2
  dropout_rate: 0.1
  beta_kl_weight: 1.0
  generation_max_time_horizon: 10000.0 # ns
  generation_max_events: 200

training_options:
  batch_size: 64
  lr: 0.001
  lr_schedule_t_max: 100 # T_max for CosineAnnealingLR, typically num_epochs
  lr_schedule_eta_min: 0.0 # eta_min for CosineAnnealingLR
  weight_decay: 0.01
  epochs: 100
  save_epochs: 5 # Save checkpoint every N epochs
  num_workers: 4
  precision: "32-true" # e.g., "bf16-mixed", "32-true"
  test_precision: "32-true"