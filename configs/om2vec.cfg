project_name: "om2vec"
project_save_dir: "./experiment_logs"
training: true
accelerator: "gpu" # or "cpu"
num_devices: 1
dataloader: "prometheus" # Corresponds to PrometheusDataModule
checkpoint: ""
resume_training: false
logger: "wandb"

data_options:
  train_data_files: ["/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/NuMu",
                     "/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/EMinus",
                     "/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/MuMinus",
                     "/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/TauMinus",]
  valid_data_files: ["/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/NuMu",
                     "/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/EMinus",
                     "/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/MuMinus",
                     "/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/TauMinus"]
  train_data_file_ranges: [[0, 9], [0, 9], [0, 9], [0, 9]] # Ranges for each file in train_data_files
  valid_data_file_ranges: [[10, 12], [10, 12], [10, 12], [10, 12]] # Ranges for each file in valid_data_files
  shuffle_files: true
  max_seq_len: 384 # Max processing length for binning/padding & decoder loop
  time_column: "hits_t" # Column in Parquet for lists of times
  # charge_is_count: true # Implicitly, as raw_q is ones, then binned

model_name: "om2vec" # Corresponds to Om2vecModel
model_options:
  # Transformer Base Params
  d_model: 256 # Main feature dimension for Transformer
  n_head: 8    # Number of attention heads
  dim_feedforward: 1024 # Dimension of feedforward network in Transformer layers
  dropout: 0.1 # Dropout rate

  # Encoder params
  encoder_n_layers: 3 # Number of TransformerEncoderLayers
  # Input embedding dimensions for time and charge. Their sum will be projected to d_model or d_model will be used directly.
  # For simplicity, let's make the combined input embedding project to d_model.
  # Individual embedding dims for time/charge can be smaller, then concatenated and projected.
  # Or, we can make the input embedding layer output d_model directly.
  # Let's assume the input embedding layer will output d_model.
  # encoder_input_embed_dim_time: 128 # (Commented out, d_model will be used by embedding layer)
  # encoder_input_embed_dim_charge: 128 # (Commented out)

  # Latent space: total_latent_dim = 1 (for length) + learned_latent_dim
  latent_dim: 32 # Total z dim. If 32, then 1 for length, 31 learned.
  
  # Decoder (NTPP) params
  decoder_n_layers: 3 # Number of TransformerDecoderLayers
  ntpp_time_dist: "LogNormal"
  ntpp_charge_dist: "Normal"
  # KL annealing parameters
  kl_beta_start: 0.000001 # Initial beta value for KL divergence
  kl_beta_end: 0.0001     # Final beta value for KL divergence
  kl_anneal_epochs: 5 # Number of epochs to reach kl_beta_end from kl_beta_start

training_options:
  batch_size: 512
  lr: 0.0001
  lr_schedule: [5, 0.000001]
  weight_decay: 0.01
  epochs: 5
  save_epochs: 1
  num_workers: 4
  precision: "bf16-mixed"
  test_precision: "32-true"