project_name: "om2vec"
project_save_dir: "./experiment_logs"
training: true
accelerator: "gpu" # or "cpu"
num_devices: 1
dataloader: "prometheus" # Corresponds to PrometheusDataModule
checkpoint: ""
resume_training: false
logger: "wandb"

data_options:
  train_data_files: ["/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/NuMu",
                     "/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/EMinus",
                     "/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/MuMinus",
                     "/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/TauMinus",]
  valid_data_files: ["/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/NuMu",
                     "/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/EMinus",
                     "/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/MuMinus",
                     "/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/felixyu/IceCube_MC_sensors/TauMinus"]
  train_data_file_ranges: [[0, 9], [0, 9], [0, 9], [0, 9]] # Ranges for each file in train_data_files
  valid_data_file_ranges: [[10, 12], [10, 12], [10, 12], [10, 12]] # Ranges for each file in valid_data_files
  shuffle_files: true
  max_seq_len: 384 # Max processing length for binning/padding & decoder loop
  time_column: "hits_t" # Column in Parquet for lists of times
  # charge_is_count: true # Implicitly, as raw_q is ones, then binned

model_name: "om2vec" # Corresponds to Om2vecModel
model_options:
  # Encoder params
  encoder_input_embed_dim_time: 128
  encoder_input_embed_dim_charge: 128
  encoder_hidden_dim: 256
  encoder_num_layers: 6
  # Latent space: total_latent_dim = 1 (for length) + learned_latent_dim
  latent_dim: 32 # Total z dim. If 64, then 1 for length, 63 learned.
  # Decoder (NTPP) params
  decoder_hidden_dim: 256
  decoder_num_layers: 6
  ntpp_time_dist: "LogNormal"
  ntpp_charge_dist: "Normal"
  # KL annealing parameters
  kl_beta_start: 0.000001 # Initial beta value for KL divergence
  kl_beta_end: 0.0001     # Final beta value for KL divergence
  kl_anneal_epochs: 5 # Number of epochs to reach kl_beta_end from kl_beta_start

training_options:
  batch_size: 512
  lr: 0.0001
  lr_schedule: [5, 0.000001]
  weight_decay: 0.01
  epochs: 5
  save_epochs: 1
  num_workers: 4
  precision: "bf16-mixed"
  test_precision: "32-true"